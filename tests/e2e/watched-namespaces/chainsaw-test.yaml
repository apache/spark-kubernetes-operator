#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

apiVersion: chainsaw.kyverno.io/v1alpha1
kind: Test
metadata:
  name: spark-operator-dynamic-configuration-validation
spec:
  steps:
  - try:
      - apply:
          file: spark-operator-dynamic-config-1.yaml
      - sleep:
          duration: 30s
      - script:
          content:
            kubectl logs -n default $(kubectl get pods -o=name -l app.kubernetes.io/component=operator-deployment,app.kubernetes.io/name=spark-kubernetes-operator)
          check:
            (contains($stdout, 'Updating operator namespaces to [default, spark-1]')): true
      - apply:
          bindings:
            - name: SPARK_APP_NAMESPACE
              value: spark-1
          file: spark-example.yaml
      - assert:
          bindings:
          - name: SPARK_APP_NAMESPACE
            value: spark-1
          timeout: 60s
          file: "../assertions/spark-application/spark-state-transition.yaml"
      - apply:
          bindings:
            - name: SPARK_APP_NAMESPACE
              value: spark-2
          file: spark-example.yaml
      - sleep:
          duration: 60s
      - script:
          content:
            kubectl get sparkapplication spark-job-succeeded-test -n spark-2 -o json | jq ".status"
          check:
            (contains($stdout, 'null')): true
    catch:
      - podLogs:
          namespace: default
          selector: app.kubernetes.io/component=operator-deployment,app.kubernetes.io/name=spark-kubernetes-operator
      - describe:
          apiVersion: spark.apache.org/v1beta1
          kind: SparkApplication
          namespace: spark-1
      - describe:
          apiVersion: spark.apache.org/v1beta1
          kind: SparkApplication
          namespace: spark-2
    finally:
      - script:
          content: |
            kubectl delete sparkapplication spark-job-succeeded-test -n spark-1 --ignore-not-found=true
            kubectl delete sparkapplication spark-job-succeeded-test -n spark-2 --ignore-not-found=true
            kubectl replace -f spark-operator-dynamic-config-2.yaml
  - try:
      - script:
          content: |
            echo "Installing another spark operator in default-2 namespaces, watching on namespace: spark-3"
            helm install spark-kubernetes-operator -n default-2 --create-namespace -f \
            ../../../build-tools/helm/spark-kubernetes-operator/values.yaml -f \
            ../helm/dynamic-config-values-2.yaml \
            ../../../build-tools/helm/spark-kubernetes-operator/
      - apply:
          bindings:
            - name: SPARK_APP_NAMESPACE
              value: spark-3
          file: spark-example.yaml
      - sleep:
          duration: 60s
      - script:
          content:
            kubectl logs -n default-2 $(kubectl get pods -n default-2 -o=name -l app.kubernetes.io/component=operator-deployment,app.kubernetes.io/name=spark-kubernetes-operator)
          check:
            (contains($stdout, 'Updating operator namespaces to [spark-3]')): true
      - assert:
          bindings:
            - name: SPARK_APP_NAMESPACE
              value: spark-3
          timeout: 180s
          file: "../assertions/spark-application/spark-state-transition.yaml"
    catch:
      - podLogs:
          namespace: default-2
          selector: app.kubernetes.io/component=operator-deployment,app.kubernetes.io/name=spark-kubernetes-operator
      - describe:
          apiVersion: spark.apache.org/v1beta1
          kind: SparkApplication
          namespace: spark-3
      - get:
          apiVersion: v1
          kind: Pod
          namespace: spark-3
      - events:
          namespace: spark-3
    finally:
      - script:
          timeout: 60s
          content: |
            kubectl delete sparkapplication spark-job-succeeded-test -n spark-3 --ignore-not-found=true
            helm uninstall spark-kubernetes-operator -n default-2
            kubectl delete namespace default-2 --ignore-not-found=true
            kubectl delete namespace spark-3 --ignore-not-found=true
